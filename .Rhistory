)
\
q
""
remove.packages("xlsx")
library(rJava)
library(xlsxjars)
install.packages("xlsx") ##翻墙
install.packages("xlsx")
library(rJava)
library(xlsxjars)
library(xlsx)
camerasData <- read.xlsx("./data/cameras.xlsx", sheetIndex = 1, header = TRUE)
fileUrl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.xlsx?accessType=DOWNLOAD"
download.file(fileUrl, destfile = "./data/cameras.xlsx")
camerasData <- read.xlsx("./data/cameras.xlsx", sheetIndex = 1, header = TRUE)
library(xlsx)
camerasData <- read.xlsx("./data/cameras.xlsx", sheetIndex = 1, header = TRUE)
head(camerasData)
library(XML)
install.packages("XML")
library(XML)
fileUrl <- "http://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[1]
rootNode[[1]
]
rootNode[[1][1]]
rootNode[[1]][[1]]
xmlSApply(rootNode, xmlValue)
fileUrl <- "http://www.w3schools.com/xml/simple.xml"
install.packages("jsonlite")
library(jsonlite)
library("jsonlite")
jsonData <- fromJSON(fileUrl)
fileUrl <- "https://www.w3schools.com/xml/simple.xml"
jsonData <- fromJSON(fileUrl)
fileUrl <- "https://api.github.com/users/jtleek/repos"
jsonData <- fromJSON(fileUrl)
names(jsonData)
names(jsonData$owner)
names(jsonData$owner$login)
names(jsonData$owner$id)
names((jsonData$owner)$id)
(jsonData$owner)$id
data(iris)
myjson <- toJSON(iris, pretty = TRUE)
cat(myjson)
iris2 <- fromJSON(myjson)
head(iris2)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv "
download.file(fileUrl, "./data/housing.csv")
housingData <- read.csv("./data/housing.csv", sep = ",", header = TRUE)
head(housingData)
class(housingData)
length(housingData)
length(housingData[housingData$VAL != "bb")
length(housingData[housingData$VAL != "bb"])
length(housingData[housingData$VAL != "bb",])
length(housingData[housingData$VAL != "bb" & housingData$VAL >= 1000000,])
length(housingData[!is.na(housingData$VAL) & housingData$VAL >= 1000000,])
length(housingData[!is.na(housingData$VAL),])
housingData[!is.na(housingData$VAL),]
length(housingData[!is.na(housingData$VAL),])
housingData2 <- housingData[!is.na(housingData$VAL),]
length(housingData2)
housingData2$VAL
val <- housingData2[housingData2$VAL >= 02, ]$VAL
length(val)
val <- housingData2[housingData2$VAL >= 24, ]$VAL
length(val)
fileUr <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx "
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx "
download.file(fileUrl, "./data/gas.xlsx")
nrows <- 18:23
ncols <- 7:15
dat <- read.xlsx("./data/gas.xlsx", sheetIndex = 1, rowIndex = nrows, colIndex = ncols, header = TRUE)
sum(dat$Zip*dat$Ext,na.rm=T)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml "
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
?xmlTreeParse
doc <- xmlTreeParse(fileUrl, useInternalNode = TRUE)
doc <- xmlTreeParse(fileUrl, useInternalNode = TRUE)
fileUrl
fileUrl
doc <- xmlTreeParse(fileUrl, useInternalNode = TRUE)
fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternalNode = TRUE)
savehistory("command1.txt")
rootNode <- xmlRoot(doc)
rootNode
names(rootNode)
names(rootNode$row)
names(rootNode[,row])
xmlName(rootNode)
names(rootNode[1])
names(rootNode[[1]])
names(rootNode[[1]][2])
names(rootNode[[[2]]])
names(rootNode[[2]])
xmlSApply(rootNode, xmlValue)
names(rootNode[1])
names(rootNode[1][1])
names(rootNode[1][1][2])
names(rootNode[[1]][1])
names(rootNode[[1]][[1])
names(rootNode[[1]][[1]])
xpathSApply(rootNode,"//zipcode",xmlValue)
zipcode <- xpathSApply(rootNode,"//zipcode",xmlValue)
length(zipcode == "21231")
length(zipcode)
length(zipcode[zipcode == "21231"])
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv "
download.file(fileUrl, destfile = "./data/community.csv")
communityData <- fread("./data/community.csv")
communityData <- read.table("./data/community.csv")
head(communityData)
View(communityData)
View(communityData)
View(communityData)
View(communityData)
communityData <- read.table("./data/community.csv", header = T)
head(communityData)
View(communityData)
View(communityData)
DT[,mean(pwgtp15),by=SEX]
DT <- read.table("./data/community.csv", header = T)
DT[,mean(pwgtp15),by=SEX]
DT <- read.csv("./data/community.csv", sep = ",", header = T)
DT[,mean(pwgtp15),by=SEX]
sapply(split(DT$pwgtp15,DT$SEX),mean)
mean(DT$pwgtp15,by=DT$SEX)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
sapply(split(DT$pwgtp15,DT$SEX),mean)
tapply(DT$pwgtp15,DT$SEX,mean)
sum(dat$Zip*dat$Ext,na.rm=T)
DT[,mean(pwgtp15),by=SEX]
library(data.table)
install.packages("data.table")
DT[,mean(pwgtp15),by=SEX]
DT[,mean(DT$pwgtp15),by=SEX]
DT[,mean(pwgtp15),by=SEX]
DT <- data.table(DT)
library(data.table)
DT[,mean(pwgtp15),by=SEX]
DT <- data.table(DT)
DT[,mean(pwgtp15),by=SEX]
head(housingData$FES)
savehistory("command.txt")
q()
install.packages("rmysql")
R --version
Sys.getenv("SHELL")
install.packages('RMySQl')
install.packages("RMySQL", type="source")
R CMD INSTALL C:\Users\hp\AppData\Local\Temp\Rtmp0EVdLu\downloaded_packages
CMD INSTALL C:\Users\hp\AppData\Local\Temp\Rtmp0EVdLu\downloaded_packages\RMySQL_0.9-3.tar.gz
Sys.getenv("PATH")
Sys.getenv("PATH")
system('g++ -v')
system('g++ -v')
Sys.getenv("PATH")
Sys.getenv("PATH")
system('g++ -v')
install.packages("RMySQL", type="source")
CMD INSTALL C:\Users\hp\AppData\Local\Temp\Rtmpi6HgVH\downloaded_packages\RMySQL_0.9-3.tar.gz
R CMD INSTALL C:\Users\hp\AppData\Local\Temp\Rtmpi6HgVH\downloaded_packages\RMySQL_0.9-3.tar.gz
library(RMySQL)
con <- url("http://scholar.google.com.hk/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode = readLines(con)
htmlCode = readLines(con)
con <- url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode = readLines(con)
htmlCode = readLines(con)
con <- url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode = readLines(con)
con <- url("http://www.baidu.com/index.php?tn=monline_5_dg")
htmlCode = readLines(con)
con.close()
close(con)
htmlCode
library(httr)
library(httr)
source('~/Desktop/COURSERA/GettingandCleaningData/Quit2_1.R')
source('~/Desktop/COURSERA/GettingandCleaningData/Quit2_1.R')
source('~/Desktop/COURSERA/GettingandCleaningData/Quit2_1.R')
source('~/Desktop/COURSERA/GettingandCleaningData/Quit2_1.R')
source('~/Desktop/COURSERA/GettingandCleaningData/Quit2_1.R')
install.packages(c(‘jsonlite’,’httpuv’,httr’))
install.packages(c("jsonlite","httpuv","httr"))
library(c("jsonlite","httpuv","httr"))
library("jsonlite")
library("httpuv")
library("httr")
source('~/Desktop/COURSERA/GettingandCleaningData/Quit2_1.R')
getwd9)
getwd()
source('~/Desktop/COURSERA/GettingandCleaningData/Quit2_1.R')
view(R)
source('~/Desktop/COURSERA/GettingandCleaningData/Quit2_1.R')
source('~/Desktop/COURSERA/GettingandCleaningData/Quit2_1.R')
source('~/Desktop/COURSERA/GettingandCleaningData/Quit2_1.R')
myjson
source('~/Desktop/COURSERA/GettingandCleaningData/Quit2_1.R')
myjson
source('~/Desktop/COURSERA/GettingandCleaningData/Quit2_1.R')
acs <- read.csv("./data/getdata_data_ss06pid.csv", header = T, sep = ",")
library(rmysql)
library(RMySQL)
sqldf("select * from acs where AGEP < 50 and pwgtp1")
?dbSendQuery
install.packages("sqldf")
library(sqldf)
sqldf("select * from acs where AGEP < 50 and pwgtp1")
class(acs)
options(sqldf.driver)
options(sqldf.driver = "MySQL")
options(gsubfn.engine = "R")
library(RMySQL)
library(sqldf)
sqldf("select * from acs where AGEP < 50 and pwgtp1")
work_class_scores <- work.class_scores
work_class_scores <- acs
sqldf("select * from acs where AGEP < 50 and pwgtp1")
sqldf("select * from acs where AGEP < 50 and pwgtp1", drv = "MySQL")
require(sqldf)
sqldf("select * from acs where AGEP < 50 and pwgtp1", drv = "MySQL")
?sqldf
sqldf("select * from acs where AGEP < 50 and pwgtp1", user = "localhost", password = "Lucy-1028")
unique(acs$AGEP)
url <- "http://biostat.jhsph.edu/~jleek/contact.html "
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
htmlpage<-htmlParse(url,encoding="UTF-8")
doc <- htmlParse(url, encoding="UTF-8")
library(XML)
doc <- htmlParse(url, encoding="UTF-8")
?XML
??XML
xpathSApply(doc)
n <- readHTMLTable(doc)
source('~/Desktop/COURSERA/GettingandCleaningData/GetHTML.R')
source('~/Desktop/COURSERA/GettingandCleaningData/GetHTML.R')
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
con = url(url)
htmlcode = readLines(con)
nchar(htmlcode[10])
nchar(htmlcode[20])
nchar(htmlcode[30])
nchar(htmlcode[100])
nchar(htmlcode[11])
nchar(htmlcode[31])
nchar(htmlcode[101])
close(con)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for "
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
con = url(url)
htmlcode = readLines(con)
htmlcode[9]
nrow(htmlcode)
data <- data.frame(htmlcode)
htmlcode[1]
htmlcode[2]
htmlcode[3]
htmlcode[4]
htmlcode[5]
htmlcode[100]
nchar(htmlcode[1])
nchar(htmlcode[2])
nchar(htmlcode[3])
nchar(htmlcode[4])
nchar(htmlcode[5])
nchar(htmlcode[6])
nchar(htmlcode[7])
nchar(htmlcode[8])
nchar(htmlcode[9])
htmlcode[9]
htmlcode[10]
htmlcode[11]
head(htmlcode)
head(htmlcode, 15)
?read.delim
fwk <- read.delim(textConnection(htmlcode), sep = "-", strip.white=TRUE)
fwk <- read.delim(textConnection(htmlcode), sep = "-", strip.white = T)
fwk <- data.frame(htmlcode)
head(fwk)
nrows(htmlcode)
nrow(htmlcode)
length(htmlcode)
htmlcode <- htmlcode[5:length(htmlcode)]
head(htmlcode)
?data.frame
?replace
htmlcode_replace <- replace(htmlcode, "-", " ")
head(htmlcode_replace)
?apply
htmlcode_replace <- sub("-", " ", htmlcode)
head(htmlcode_replace)
?sub
htmlcode_replace <- gsub("-", " ", htmlcode)
?sub
htmlcode_replace <- gsub("-", " ", htmlcode)
?sub
head(htmlcode_replace)
fwk <- data.frame(htmlcode)
head(fwk)
fwk <- data.frame(htmlcode_replace)
head(fwk)
cat(htmlcode_replace, file = "myfile.txt")
fwk <- read.table("myfile.txt", header = F, sep = " ")
head(fwk)
View(iris)
View(fwk)
for(i in 1:length(htmlcode_replace)){}
for(i in 1:length(htmlcode_replace)){
write(paste(htmlcode_replace[i], "\n\r", sep = " "), append = T)
}
for(i in 1:length(htmlcode_replace)){
+     write(paste(htmlcode_replace[i], "\n\r", sep = " "), file = "myfile.txt", append = T)
+ }
for(i in 1:length(htmlcode_replace)){
+     write(paste(htmlcode_replace[i], "\n\r", sep = " "), file = "myfile.txt", append = T)
+ }
for(i in 1:length(htmlcode_replace)) write(paste(htmlcode_replace[i], "\n\r", sep = " "), file = "myfile.txt", append = T)
for(i in 1:length(htmlcode_replace)) write(paste(htmlcode_replace[i], "\n", sep = " "), file = "myfile.txt", append = T)
for(i in 1:length(htmlcode_replace)) write(htmlcode_replace[i], file = "myfile.txt", append = T)
fwk <- read.table("myfile.txt", header = F, sep = " ")
View(fwk)
fwk <- fwk[, !is.na(fwk[1,])]
View(fwk)
fwk <- fwk[!is.na(fwk[,4]), ]
sum(fwk[, 4])
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://data.baltimorecity.gov/Culture-Arts/Restaurants/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl, destfile = "./data/restaurants.csv")
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl, destfile = "./data/restaurants.csv")
?download.file
download.file(fileUrl, destfile = "./data/restaurants.csv", method = "RCurl")
download.file(fileUrl, destfile = "./data/restaurants.csv", method = "internal")
restData <- read.csv("./data/restaurants.csv")
head(restData)
restData$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
table(restData$nearMe)
restData$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
head(restData)
restData$zipWrong = ifelse(restData$zipCode <0, T, F)
table(restData$zipWrong)
table(restData$zipWrong, restData$zipCode <0)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv "
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile = "./data/communities.csv", method = "internal")
communitiesData <- read.csv("./data/communities.csv")
head(communitiesData)
communitiesData$morethan <- ifelse(communitiesData$AGS == 6, T, F)
table(communitiesData$morethan)
communitiesData <- read.csv("./data/communities.csv")
communitiesData$agricultureLogical <- ifelse(communitiesData$AGS == 6, T, F)
table(communitiesData$agricultureLogical)
which(communitiesData$agricultureLogical == T)
communitiesData$agricultureLogical <- ifelse(communitiesData$AGS == 6 & communitiesData$ACR== 3, T, F)
which(communitiesData$agricultureLogical == T)
library(jpeg)
install.packages(jpeg)
install.packages("jpeg")
library(jpeg)
?jpeg.read
??jpeg
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
file.download(fileUrl, destfile = "./data/q2.jpeg", method = "Internal")
file.downloads(fileUrl, destfile = "./data/q2.jpeg", method = "Internal")
file.downLoad(fileUrl, destfile = "./data/q2.jpeg", method = "Internal")
download.file(fileUrl, destfile = "./data/q2.jpeg", method = "Internal")
download.file(fileUrl, destfile = "./data/q2.jpeg", method = "internal")
readJPEG("./data/q2.jpeg", native = T)
jpedData <- readJPEG("./data/q2.jpeg", native = T)
ncol(jpedData)
ncol(jpedData)
rcol(jpedData)
nrow(jpedData)
quantile(jpedData)
names(jpegData)
name(jpegData)
names(jpedData)
quantile(jpedData, probs=seq(0, 1,0.1))
jpedData <- readJPEG("./data/q2.jpeg", native = TRUE)
jpedData <- readJPEG("./data/q2.jpg", native = T)
download.file(fileUrl, destfile = "./data/q2.jpg", method = "internal")
jpedData <- readJPEG("./data/q2.jpeg", native = TRUE)
jpedData <- readJPEG("./data/q2.jpg", native = TRUE)
quantile(jpedData, probs=seq(0, 1,0.1))
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "./data/product.csv", method = "internal")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl, destfile = "./data/education.csv", method = "internal")
productData <- read.csv("./data/product.csv")
educationData <- read.csv("./data/education.csv")
head(productData, 3)
head(productData,)
head(productData)
head(educationData)
names(productData)
names(educationData)
mergedData <- merge(productData, educationData, by.x = "x", by.y = "CountryCode", all = T)
mergedData <- merge(productData, educationData, by.x = "X", by.y = "CountryCode", all = T)
head(mergedData)
View(mergedData)
mergedData <- merge(productData, educationData, by.x = "X", by.y = "CountryCode", all = T)
names(mergedData)
nrow(mergedData[!is.na(mergedData[,1]),])
x
mergedData$X
productData <- read.csv("./data/product.csv")
educationData <- read.csv("./data/education.csv")
head(productData)
head(educationData)
mergedData <- merge(productData, educationData, by.x = "Country", by.y = "CountryCode", all = T)
View(mergedData)
mergedData <- merge(productData, educationData, by.x = "Country", by.y = "CountryCode", all = F)
View(mergedData)
nrow(mergedData)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "./data/product.csv", method = "internal")
productData <- read.csv("./data/product.csv")
head(productData)
mergedData <- merge(productData, educationData, by.x = "X", by.y = "CountryCode", all = T)
nrow(mergedData)
nrow(mergedData[!is.na(mergedData[,1]),])
View(mergedData)
nrow(mergedData[mergedData[,1] != ""),])
nrow(mergedData[mergedData[,1] != "",])
?Order
?order
order(mergedData$Gross.domestic.product.2012, decreasing = T)
mergedData <- mergedData[order(mergedData$Gross.domestic.product.2012, decreasing = T),]
View(mergedData)
mergedData <- mergedData[order(as.numeric(mergedData$Gross.domestic.product.2012), decreasing = T),]
View(mergedData)
mergedData$Gross.domestic.product.2012 <- as.numeric(mergedData$Gross.domestic.product.2012)
mergedData <- mergedData[order(mergedData$Gross.domestic.product.2012, decreasing = T),]
View(mergedData)
names(productData) <- c("Country", "Ranking", "Empty", "LongName", "Dollars", "Level")
rm.na(producrData[1,])
productData[na.rm(productData[,1]),]
productData[rm.na(productData[,1]),]
productData[productData[,1] != "",]
productData <- productData[productData[,1] != "",]
productData <- productData[, c(1,2,4,5,6)]
head(productData)
mergedData <- merge(productData, educationData, by.x = "Country", by.y = "CountryCode", all = T)
nrow(mergedData)
mergedData <- merge(productData, educationData, by.x = "Country", by.y = "CountryCode", all = F)
nrow(mergedData)
View(mergedData)
nrow(mergedData[mergedData$Ranking!="",]
)
mergedData <- mergedData[mergedData$Ranking!="",]
mergedData$Ranking <- as.numeric(mergedData$Ranking)
mergedData <- mergedData[order(mergedData$Ranking, decreasing = T),]
View(mergedData)
mergedData <- merge(productData, educationData, by.x = "Country", by.y = "CountryCode", all = F)
mergedData <- mergedData[mergedData$Ranking!="",]
nrow(mergedData[mergedData$Ranking!="",]
)
as.numeric("1")
class(mergedData$Ranking[1])
mergedData$Ranking <- as.numeric(as.character(mergedData$Ranking)
)
mergedData[order(mergedData$Ranking, decreasing = T),]
ave(mergedData[mergedData$Income.Group == "High income: nonOECD", mergedData$Ranking])
ave(mergedData[mergedData$Income.Group = "High income: nonOECD", mergedData$Ranking])
ave(mergedData[mergedData$Income.Group == "High income: nonOECD", mergedData$Ranking])
names(mergedData)
ave(mergedData[mergedData[,7] == "High income: nonOECD", mergedData$Ranking])
ave(mergedData[mergedData[,7] == "High income: nonOECD",])
ave(mergedData[mergedData[,7] == "High income: nonOECD",1])
class(mergedData[,7])
clevel(mergedData[,7])
level(mergedData[,7])
levels(mergedData[,7])
ave(mergedData[levels(mergedData[,7]) == "High income: nonOECD", mergedData$Ranking])
ave(mergedData[levels(mergedData[,7]) == "High income: nonOECD", ])
mean(mergedData[levels(mergedData[,7]) == "High income: nonOECD", ])
highincome <- mergedData[levels(mergedData[,7]) == "High income: nonOECD",])
highincome <- mergedData[levels(mergedData[,7]) == "High income: nonOECD",]
View(highincome)
levels(highincome[,7])
highincome <- mergedData[as.charater(mergedData[,7]) == "High income: nonOECD",]
highincome <- mergedData[as.character(mergedData[,7]) == "High income: nonOECD",]
View(highincome)
highincome <- mergedData[as.charater(mergedData[,7]) == "High income: nonOECD",]
mean(highincome$Ranking)
highincome <- mergedData[as.charater(mergedData$Income.Group) == "High income: OECD",]
highincome <- mergedData[as.charater(mergedData$"Income.Group") == "High income: OECD",]
highincome <- mergedData[as.character(mergedData$Income.Group) == "High income: OECD",]
mean(highincome$Ranking)
?quantile
View(mergedData)
orderMerge <- mergedData[order(mergedData$Ranking, decreasing = T),]
orderMerge <- mergedData[order(mergedData$Ranking),]
head(orderMerge)
highest38 <- orderMerge[1:38,]
View(highest38)
mergedData$rankingGroup <- cut(mergedData$Ranking, breaks = quantile(mergedData$Ranking, c(0,1,0.2))
)
table(mergedData$rankingGroup, mergedData$Income.Group)
